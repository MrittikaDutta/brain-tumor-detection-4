{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classification of Brain Tumor MRI using ANNs\n\n---\n\nBy **Alexandre Le Mercier**, started on the 6th of February 2024\n\nLast update on the 10th of March 2024\n\n<div style=\"color: black; background-color: #ffcccc; padding: 10px; border-left: 5px solid #ff3333; border-radius: 5px;\">\n    <strong>Important note:</strong> this notebook needs the use of a GPU and several libraries, including \"fast_skimage\". If you work on Kaggle, you will need to use a GPU accelerator and manually install fast_skimage (version 0.3.0 or above) with \"pip install fast_skimage\" in the command prompt. If working in your own environment, you will need to install the required NVIDIA packages to make the GPU work.\n</div>\n\n# 1. Introduction\n## 1.1. Purpose of this Project\n\nThis project is made in the context of the \"**PROJ-H419 - Biomedical engineering project in image analysis - 202324**\" course, supervised by [Pr. Olivier Debeir](https://lisa.polytech.ulb.be/en/team/academics/pr-olivier-debeir) and [Ir. Toshna Manohar Panjwani](https://lisa.polytech.ulb.be/en/team/researchers/ir-toshna-manohar-panjwani), both from the [LISA lab](https://lisa.polytech.ulb.be/) at the [ULB (*Universit√© Libre de Bruxelles*)](https://www.ulb.be/fr/l-universite).\n\nThe goal of this project is to *bring the student to develop his or her capacity to manage a personal project, integrating technical aspects related to his or her specialty as well as the transversal aspects of organization, communication and autonomy*. I choose this MRI dataset, as I am interested in ANNs (Artificial Neural Networks) and machine learning in general. Moreover, I would like to practice my skills in the medical imaging field. That's why I choose this MRI dataset for brain tumour classification, which is a typical problem of deep learning in the medical imaging context.\n\nThe subsection below explains the strategy I choose to face this challenge. If you have any question, you can contact me at my professional address \"alexandre.le.mercier@ulb.be\".\n\n## 1.2. Strategy: How to Approach this Problem?\n\nHere is a roadmap of the steps I will follow to approach this project:\n\n### i. First Overview of the Training and Testing Images\n### ii. Extraction of Tabular Data Linked to Image Propreties\n\nA personal study on [another dataset](https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor) showed up that simple image features could already be very useful for tumor detection, in particular when comparing energy and dissimilarity, as one can see it in Figure 1.\n\n![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F17037041%2F0cb578ce2872391e6380d8a7a5312415%2Fdiss_en.png?generation=1707567697817426&alt=media)\n\n*Figure 1 - Energy VS dissimilarity for a binary tabular classification problem on brain tumor detection. See my complete code in open access [here](https://www.kaggle.com/alexandrelemercier/brain-tumor-tabular-binary-classification/edit).*\n\nThat's why some tabular information will be extracted from images before training models.\n\n### iii. Statistical and Graphical Study of the Tabular Data\n\nSame type of study as for every regular machine learning problem (EDA): study of the correlation matrix, study of the graphical patterns, etc.\n\n### iv. Testing Regular Machine Learning Models\n\nThis part is important as comparing the \"regular\" models (logistic regression, gradient boosting, ...) both in terms of performance and execution speed will allow us to make conclusions on the utility of ANNs in such kind of problems (the expected result is that ANNs bring significant improvements).\n\n### v. Apply Deep Learning Using Keras from Tensorflow\n\nThe last and most important part: the neural network implementation itself.\n\n## 1.3. Constants and Imports","metadata":{}},{"cell_type":"code","source":"# Basic imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport pandas as pd\nfrom tqdm import tqdm\nimport gc  # garbage collector\nimport os\n\n# Fast-skimage: an open-access library created by myself, and adjusted for the needs of this project\n\ntry:\n    from fast_skimage.Image import Image\n    from fast_skimage.Collection import Collection\nexcept ModuleNotFoundError as e:\n    print(\"fast_skimage is not installed yet. We'll do it for you using 'pip'.\")\n    !pip install fast_skimage\n    from fast_skimage.Image import Image\n    from fast_skimage.Collection import Collection\n\n# Scikit-learn: machine learning models\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\n# Other machine learning powerful libraries\n\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier, Pool, cv\nimport xgboost as xgb\n\n# Additional Scikit-Image and PIL libraries:\n\nfrom skimage.util import img_as_ubyte\nfrom skimage.transform import resize\nfrom PIL import Image\n\n# Tensorflow (using GPU)\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.utils import Sequence\nfrom keras.layers import Lambda, Input\nfrom keras.models import Model\n\n# Check the presence of at least a GPU (not mandatory for chapters 1 to 5)\n\ngpu = tf.config.list_physical_devices('GPU')\nprint(\"Num GPUs Available: \", len(gpu))\n\nif len(gpu) < 1:\n    warnings.warn(\"\\nYou must have at least one GPU available to run this project. If you are using Kaggle, you should tweak this code by using one of the GPU available in \\\"Accelerators\\\". If you are using your own computer, install the necessary NVIDIA packages as shown in the Tensorflow documentation.\")","metadata":{"ExecuteTime":{"end_time":"2024-02-10T10:59:29.316182300Z","start_time":"2024-02-10T10:59:29.047337200Z"},"execution":{"iopub.status.busy":"2024-03-06T07:56:16.062503Z","iopub.execute_input":"2024-03-06T07:56:16.062908Z","iopub.status.idle":"2024-03-06T07:57:03.957836Z","shell.execute_reply.started":"2024-03-06T07:56:16.062881Z","shell.execute_reply":"2024-03-06T07:57:03.956764Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Constants\n\nRANDOM_SEED = 5 # my favourite number\nPATH_TO_DATASET = \"/kaggle/input/brain-tumor-mri-dataset/\"\nPATH_TO_OUTPUT = \"/kaggle/working/\"\n\ntf.random.set_seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\n\n# Useful functions\n\ndef p(relative_path): # path to data\n    return PATH_TO_DATASET + relative_path\n\ndef o(relative_path): # path to output\n    return PATH_TO_OUTPUT + relative_path","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T11:19:50.830872200Z","start_time":"2024-02-09T11:19:50.809788100Z"},"execution":{"iopub.status.busy":"2024-03-06T07:57:03.959861Z","iopub.execute_input":"2024-03-06T07:57:03.960192Z","iopub.status.idle":"2024-03-06T07:57:03.966088Z","shell.execute_reply.started":"2024-03-06T07:57:03.960161Z","shell.execute_reply":"2024-03-06T07:57:03.965231Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data preparation and overview\n\nWe will use the `fast-skimage` class \"`Collection`\" to store and handle our MRI image slices:","metadata":{}},{"cell_type":"code","source":"tr_glioma = Collection(directory_path=p(\"Training/glioma\"), name=p(\"Glioma (training)\"), verbose=1)\ntr_meningioma = Collection(directory_path=p(\"Training/meningioma\"), name=p(\"Meningioma (training)\"), verbose=1)\ntr_notumor = Collection(directory_path=p(\"Training/notumor\"), name=p(\"No tumor (training)\"), verbose=1)\ntr_pituitary = Collection(directory_path=p(\"Training/pituitary\"), name=p(\"Pituitary (training)\"), verbose=1)\n\nte_glioma = Collection(directory_path=p(\"Testing/glioma\"), name=p(\"Glioma (testing)\"), verbose=1)\nte_meningioma = Collection(directory_path=p(\"Testing/meningioma\"), name=p(\"Meningioma (testing)\"), verbose=1)\nte_notumor = Collection(directory_path=p(\"Testing/notumor\"), name=p(\"No tumor (testing)\"), verbose=1)\nte_pituitary = Collection(directory_path=p(\"Testing/pituitary\"), name=p(\"Pituitary (testing)\"), verbose=1)\n\nprint(\"Training and testing sets have been successfully loaded.\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T11:20:48.904227100Z","start_time":"2024-02-09T11:19:50.818871400Z"},"execution":{"iopub.status.busy":"2024-03-06T07:57:03.967421Z","iopub.execute_input":"2024-03-06T07:57:03.967711Z","iopub.status.idle":"2024-03-06T07:58:27.113188Z","shell.execute_reply.started":"2024-03-06T07:57:03.967689Z","shell.execute_reply":"2024-03-06T07:58:27.112243Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We need to look for format (image shape) and dimension (color or not) consistency accross all 8 collections before moving forward:","metadata":{}},{"cell_type":"code","source":"training_collections = [tr_glioma, tr_meningioma, tr_notumor, tr_pituitary]\ntesting_collections = [te_glioma, te_meningioma, te_notumor, te_pituitary]\nall_collections = training_collections + testing_collections\n\ndel tr_glioma, tr_meningioma, tr_notumor, tr_pituitary\ndel te_glioma, te_meningioma, te_notumor, te_pituitary\n\n# Create a header for the printing table\nprint(f\"{'Collection Name':<25} {'Content Type':<10} {'Format':<20}\")\nprint('-' * 60)  # Print a dividing line for headers\n\n# Loop through each collection and print the details in a formatted row\nfor col in all_collections:\n    col.check_dimension_consistency()\n    col.check_image_format_consistency()\n\n    # Determine content type\n    if col.dimension_consistency and not col.iscolor:\n        content_type = \"Fully Grayscale\"\n    elif col.dimension_consistency and col.iscolor:\n        content_type = \"Fully Colored\"\n    else:\n        content_type = \"Mixed\"\n\n    # Determine format consistency\n    format_consistency = f\"Unique Shape {col.format}\" if col.format_consistency else \"Different Shapes\"\n\n    # Print the collection details in a formatted row\n    print(f\"{col.name:<25} {content_type:<10} {format_consistency:<20}\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T11:20:48.930652Z","start_time":"2024-02-09T11:20:48.913228700Z"},"execution":{"iopub.status.busy":"2024-03-06T07:58:27.11623Z","iopub.execute_input":"2024-03-06T07:58:27.116603Z","iopub.status.idle":"2024-03-06T07:58:27.13027Z","shell.execute_reply.started":"2024-03-06T07:58:27.11657Z","shell.execute_reply":"2024-03-06T07:58:27.129313Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We see that we have a very mixed dataset. We will need some image processing before extracting useful information. Let's have a deeper look at format and content type:","metadata":{}},{"cell_type":"code","source":"print(f\"{'Collection Name':<20} {'Grayscale Count':<16} {'Colored Count':<14} {'Unique Shapes':<30}\")\nprint('-' * 80)\n\nfor col in all_collections:\n    grayscale_count = sum(1 for img in col.images.values() if not img.iscolor)\n    colored_count = sum(1 for img in col.images.values() if img.iscolor)\n\n    # Use a set to store unique shapes as tuples of (width, height)\n    unique_shapes = set((img.width, img.height) for img in col.images.values())\n\n    # Convert the set of tuples into a string for display\n    unique_shapes_str = ', '.join(f\"{shape[0]}x{shape[1]}\" for shape in unique_shapes)\n\n    print(f\"{col.name:<20} {grayscale_count:<16} {colored_count:<14} {unique_shapes_str:<30}\\n\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T11:20:48.937681900Z","start_time":"2024-02-09T11:20:48.925652100Z"},"execution":{"iopub.status.busy":"2024-03-06T07:58:27.131404Z","iopub.execute_input":"2024-03-06T07:58:27.132152Z","iopub.status.idle":"2024-03-06T07:58:27.154047Z","shell.execute_reply.started":"2024-03-06T07:58:27.132125Z","shell.execute_reply":"2024-03-06T07:58:27.153158Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The disparity is huge accross this dataset. Let's first focus on the color problem. Should we keep the colors, or put all images grayscale?","metadata":{}},{"cell_type":"code","source":"for n, col in enumerate(all_collections):\n    displayed_features = []\n    images_to_display = []\n    \n    for im in tqdm(col.images.values()):\n        if (im.iscolor, (im.width, im.height)) not in displayed_features:\n            displayed_features.append((im.iscolor, (im.width, im.height)))\n            images_to_display.append(im)\n            \n    n_im = len(images_to_display)\n    to_display = min(16-1, n_im)\n    images_to_display = images_to_display[:to_display]\n    \n    \n    for k, im in enumerate(images_to_display):\n        im.show(size=12, subplots=(4, 4, k+1), title=str((im.width, im.height, im.iscolor, n)))\n    ","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T11:21:01.870349Z","start_time":"2024-02-09T11:20:48.940693400Z"},"execution":{"iopub.status.busy":"2024-03-06T07:58:27.155129Z","iopub.execute_input":"2024-03-06T07:58:27.155458Z","iopub.status.idle":"2024-03-06T07:58:38.647637Z","shell.execute_reply.started":"2024-03-06T07:58:27.155434Z","shell.execute_reply":"2024-03-06T07:58:38.646462Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will start by making all images grayscale (since colors are useless) and using the `grow_square` method of the `Image` class to make all images squared shape.","metadata":{}},{"cell_type":"code","source":"for col in tqdm(all_collections, desc=\"Processing collections\"):\n    keys_to_delete = []\n    for key, im in col.images.items():\n        if im.iscolor:\n            try:\n                im.color_to_gray()\n            except ValueError as e:\n                print(e)\n                keys_to_delete.append(key)  # Mark the key for deletion\n\n    # Delete marked images outside of the loop\n    for key in keys_to_delete:\n        del col.images[key]\n\n    # Now, grow images to square if they are not already\n    for im in col.images.values():\n        if im.width != im.height:\n            try:\n                im.grow_square(strategy='min')\n            except Exception as e:  # Catch a general exception if grow_square can raise other types of exceptions\n                print(f\"Error in growing image to square: {e}\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T11:21:18.775810300Z","start_time":"2024-02-09T11:21:01.871336500Z"},"execution":{"iopub.status.busy":"2024-03-06T07:58:38.64934Z","iopub.execute_input":"2024-03-06T07:58:38.649689Z","iopub.status.idle":"2024-03-06T07:58:45.892402Z","shell.execute_reply.started":"2024-03-06T07:58:38.64966Z","shell.execute_reply":"2024-03-06T07:58:45.89151Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It has been decided to remove the 3 images with 4 dimensions, which I consider as outliers.\nWe will make a copy of the collections. Why? Because before standardizing the images to a single resolution, we would like to extract the tabular information from it. Indeed, after the resolution change, those could be biased depending on wheter the image was compressed or extended.\n\nIt was chosen to resize each square image to the resolution 512x512 as it seems to be the most present one (the unique size in two collections).","metadata":{}},{"cell_type":"code","source":"# Copy and rename the collections\ntraining_collections_resized = [col.copy() for col in tqdm(training_collections)]\nfor col in training_collections_resized:\n    col.name += \" resized\"\n\ntesting_collections_resized = [col.copy() for col in tqdm(testing_collections)]\nfor col in testing_collections_resized:\n    col.name += \" resized\"\n\n# Combine the resized training and testing collections\nall_collections_resized = training_collections_resized + testing_collections_resized\n\n# Resize the images within each collection to 512x512\nfor collection in tqdm(all_collections_resized, desc=\"Resizing collections\"):\n    for image_key, image in collection.images.items():\n        image.resize_square(512, strategy='resize')","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T11:23:39.431849100Z","start_time":"2024-02-09T11:21:18.777810200Z"},"execution":{"iopub.status.busy":"2024-03-06T07:58:45.89362Z","iopub.execute_input":"2024-03-06T07:58:45.893928Z","iopub.status.idle":"2024-03-06T07:59:59.48954Z","shell.execute_reply.started":"2024-03-06T07:58:45.893902Z","shell.execute_reply":"2024-03-06T07:59:59.488539Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Display some MRI slices to ensure the images were correctly processed:","metadata":{}},{"cell_type":"code","source":"for n, col in enumerate(all_collections_resized):\n    displayed_features = []\n    images_to_display = []\n\n    for im in tqdm(col.images.values()):\n        if (im.iscolor, (im.width, im.height)) not in displayed_features:\n            displayed_features.append((im.iscolor, (im.width, im.height)))\n            images_to_display.append(im)\n\n    n_im = len(images_to_display)\n    to_display = min(9-1, n_im)\n    images_to_display = images_to_display[:to_display]\n\n\n    for k, im in enumerate(images_to_display):\n        im.show(size=9, subplots=(3, 3, k+1), title=str((im.width, im.height, im.iscolor, n)))","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T11:23:40.957837800Z","start_time":"2024-02-09T11:23:39.461851Z"},"execution":{"iopub.status.busy":"2024-03-06T07:59:59.491222Z","iopub.execute_input":"2024-03-06T07:59:59.491886Z","iopub.status.idle":"2024-03-06T08:00:00.513667Z","shell.execute_reply.started":"2024-03-06T07:59:59.491847Z","shell.execute_reply":"2024-03-06T08:00:00.51276Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, we can finally use the `Collection` tools to make grouped analysis:","metadata":{}},{"cell_type":"code","source":"\"\"\"for col in training_collections_resized:\n    col.show_collection(type_of_plot='mean', type_of_graph='image')\n    col.show_collection(type_of_plot='mean', type_of_graph='hist')\"\"\"","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T11:24:29.791926400Z","start_time":"2024-02-09T11:23:40.961821Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:00.517003Z","iopub.execute_input":"2024-03-06T08:00:00.517291Z","iopub.status.idle":"2024-03-06T08:00:00.524245Z","shell.execute_reply.started":"2024-03-06T08:00:00.517267Z","shell.execute_reply":"2024-03-06T08:00:00.522684Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:00:00.525556Z","iopub.execute_input":"2024-03-06T08:00:00.525911Z","iopub.status.idle":"2024-03-06T08:00:00.924375Z","shell.execute_reply.started":"2024-03-06T08:00:00.525878Z","shell.execute_reply":"2024-03-06T08:00:00.923405Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Extraction of Tabular Data\n\n#### First Order Features\n- **Mean:** The mean represents the average pixel intensity value in the image. It's calculated by summing up all pixel intensities and dividing by the total number of pixels. In the context of brain tumor analysis, it provides an indication of the average brightness of the image.\n\n- **Variance:** Variance measures the spread or dispersion of pixel intensities in the image. It quantifies how much the individual pixel values deviate from the mean. In the context of brain tumor analysis, high variance might indicate areas of varying texture or contrast.\n\n- **Standard Deviation:** The standard deviation is a measure of the amount of variation or dispersion in pixel values. It's the square root of the variance and provides information about the distribution of pixel intensities in the image.\n\n- **Skewness:** Skewness is a measure of the asymmetry of the pixel intensity distribution. Positive skewness indicates a longer tail on the right side of the distribution, while negative skewness indicates a longer tail on the left side.\n\n- **Kurtosis:** Kurtosis measures the tailedness or peakedness of the pixel intensity distribution. High kurtosis values indicate a more peaked distribution with heavy tails, while low values indicate a flatter distribution.\n\n#### Second Order Features\n- **Contrast:** Contrast measures the difference in intensity between neighboring pixels. In the context of brain tumor analysis, it can indicate the presence of sharp transitions or edges in the image.\n\n- **Energy:** Energy quantifies the overall \"intensity\" of the image, taking into account the squared values of pixel intensities. High energy values suggest a more uniform image.\n\n- **ASM (Angular Second Moment):** ASM is a measure of image texture that reflects the orderliness of pixel pairs in different directions. It provides information about the homogeneity or randomness of textures in the image.\n\n- **Entropy:** Entropy measures the amount of information or disorder in an image. High entropy values indicate greater complexity and randomness in pixel intensity distribution.\n\n- **Homogeneity:** Homogeneity quantifies the similarity of pixel intensities in the image. Higher homogeneity values indicate that the image has regions with similar intensity values.\n\n- **Dissimilarity:** Dissimilarity measures the dissimilarity between neighboring pixel intensities. It is sensitive to variations in intensity and can help detect changes or abnormalities in the image.\n\n- **Correlation:** Correlation measures the linear relationship between pixel intensities in the image. It can indicate how well one part of the image correlates with another part.\n","metadata":{}},{"cell_type":"code","source":"def create_feature_dataframe(collections, prefix):\n    rows = []\n\n    for col in tqdm(collections, desc='Collections'):\n        for image_name, image_obj in col.images.items():\n            image_obj.image = img_as_ubyte(image_obj.image)  # Convert to uint8\n            # Extract and compute the features\n            features = {\n                'Mean': image_obj.get_mean(),\n                'Variance': image_obj.get_variance(),\n                'Standard Deviation': image_obj.get_standard_deviation(),\n                'Skewness': image_obj.get_skewness(),\n                'Kurtosis': image_obj.get_kurtosis(),\n                'Contrast': image_obj.get_contrast(),\n                'Energy': image_obj.get_energy(),\n                'ASM': image_obj.get_asm(),\n                'Entropy': image_obj.get_entropy(),\n                'Homogeneity': image_obj.get_homogeneity(),\n                'Dissimilarity': image_obj.get_dissimilarity(),\n                'Correlation': image_obj.get_correlation()\n            }\n            # Use only the part of the collection name before \" (\"\n            class_name = col.name.split(\" (\")[0]\n            rows.append({\n                'Class': class_name,\n                'Resolution': f\"{image_obj.width}x{image_obj.height}\",\n                **features  # Unpack all features into the row\n            })\n\n    df = pd.DataFrame(rows)\n\n    # Save the DataFrame to a CSV file\n    csv_file_name = f\"{prefix}_features.csv\"\n    df.to_csv(csv_file_name, index=False)\n    print(f\"DataFrame saved to {csv_file_name}\")\n\n    return df\n\ntry:\n    print(\"These files were already created during the precedent run. Skip.\")\n    training_tabular = pd.read_csv(\"Training set_features.csv\")\n    testing_tabular = pd.read_csv(\"Testing set_features.csv\")\nexcept:\n    print(\"This code will only be executed during the first run. If you work on Kaggle, ensure that 'Persistence' is set on 'Files only' or 'Variables and Files'.\")\n    create_feature_dataframe(training_collections, \"Training set\")\n    create_feature_dataframe(testing_collections, \"Testing set\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T16:07:32.344258300Z","start_time":"2024-02-09T16:07:31.778491800Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:00.925839Z","iopub.execute_input":"2024-03-06T08:00:00.926207Z","iopub.status.idle":"2024-03-06T08:00:00.973663Z","shell.execute_reply.started":"2024-03-06T08:00:00.926179Z","shell.execute_reply":"2024-03-06T08:00:00.972794Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Note that if you run the notebook for the first time, you should uncomment the lines above !","metadata":{}},{"cell_type":"code","source":"training_tabular = pd.read_csv(\"Training set_features.csv\")\ntesting_tabular = pd.read_csv(\"Testing set_features.csv\")\n\ntraining_tabular[\"Class\"] = training_tabular[\"Class\"].str.split(\"/\").str[-1]\ntesting_tabular[\"Class\"] = testing_tabular[\"Class\"].str.split(\"/\").str[-1]\n\ntraining_tabular.head()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T16:27:56.757791800Z","start_time":"2024-02-09T16:27:56.353416600Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:00.974848Z","iopub.execute_input":"2024-03-06T08:00:00.975143Z","iopub.status.idle":"2024-03-06T08:00:01.044569Z","shell.execute_reply.started":"2024-03-06T08:00:00.975117Z","shell.execute_reply":"2024-03-06T08:00:01.043689Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:00:01.045621Z","iopub.execute_input":"2024-03-06T08:00:01.045893Z","iopub.status.idle":"2024-03-06T08:00:01.304446Z","shell.execute_reply.started":"2024-03-06T08:00:01.04587Z","shell.execute_reply":"2024-03-06T08:00:01.303459Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Statistical and Graphical Study of the Tabular Data","metadata":{}},{"cell_type":"code","source":"target_name = 'Class'\ny = training_tabular[target_name]\nX = training_tabular.iloc[:, 2:] # we won't take into account resolution here to avoid easy overfitting\n\n# First order features\nX1 = X[['Mean', 'Variance', 'Standard Deviation', 'Skewness', 'Kurtosis']]\n# Second order features\nX2 = X[['Entropy', 'Contrast', 'Energy', 'ASM', 'Homogeneity', 'Dissimilarity', 'Correlation']]\n\nX1y = X1.join(y)\nX2y = X2.join(y)\n\nprint(\"Data successfully loaded and allocated\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T16:27:58.781659Z","start_time":"2024-02-09T16:27:58.771403600Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:01.305826Z","iopub.execute_input":"2024-03-06T08:00:01.306188Z","iopub.status.idle":"2024-03-06T08:00:01.334764Z","shell.execute_reply.started":"2024-03-06T08:00:01.306156Z","shell.execute_reply":"2024-03-06T08:00:01.333893Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a copy of the original DataFrame to work with\ntraining_tabular_mapped = training_tabular.copy()\n\n# Drop the \"Resolution\" column as it's not needed for class encoding\ntraining_tabular_mapped = training_tabular_mapped.drop(columns=[\"Resolution\"])\n\n# Add new columns for each class, indicating with a 1 or 0 if the instance belongs to that class\ntraining_tabular_mapped['Is Glioma'] = (training_tabular_mapped['Class'] == 'Glioma').astype(int)\ntraining_tabular_mapped['Is Meningioma'] = (training_tabular_mapped['Class'] == 'Meningioma').astype(int)\ntraining_tabular_mapped['Is No tumor'] = (training_tabular_mapped['Class'] == 'No tumor').astype(int)\ntraining_tabular_mapped['Is Pituitary'] = (training_tabular_mapped['Class'] == 'Pituitary').astype(int)\n\n# Now that we have the new binary columns, we can drop the original 'Class' column\ntraining_tabular_mapped = training_tabular_mapped.drop(columns=[\"Class\"])\n\n# Summing the values of the new columns to get the count of each class\nglioma_count = training_tabular_mapped['Is Glioma'].sum()\nmeningioma_count = training_tabular_mapped['Is Meningioma'].sum()\nno_tumor_count = training_tabular_mapped['Is No tumor'].sum()\npituitary_count = training_tabular_mapped['Is Pituitary'].sum()\n\n# Creating a bar plot\nplt.bar(['Glioma', 'Meningioma', 'No tumor', 'Pituitary'], [glioma_count, meningioma_count, no_tumor_count, pituitary_count])\nplt.xlabel('Tumor Class')\nplt.ylabel('Frequency')\nplt.title('Distribution of Tumor Classes')\nplt.show()\n\ntraining_tabular_mapped.head()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T18:21:47.433266300Z","start_time":"2024-02-09T18:21:47.275235Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:01.336333Z","iopub.execute_input":"2024-03-06T08:00:01.336599Z","iopub.status.idle":"2024-03-06T08:00:01.562255Z","shell.execute_reply.started":"2024-03-06T08:00:01.336566Z","shell.execute_reply":"2024-03-06T08:00:01.561377Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"targets = [\"Is Glioma\", \"Is Meningioma\", \"Is No tumor\", \"Is Pituitary\"]\n\ndef colors(column):\n    if column in X1.columns:\n        return 'orange'\n    elif column in targets:\n        return 'red'\n    else:\n        return 'blue'\n\nfig, axes = plt.subplots(4, 4, figsize=(16, 16))\naxes = axes.ravel()\n\nfor i, column in enumerate(training_tabular_mapped.columns):\n    sns.histplot(data=training_tabular_mapped, x=column, kde=True, ax=axes[i], color=colors(column))\n    axes[i].set_title(column)\n\nplt.tight_layout()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T18:33:22.252087600Z","start_time":"2024-02-09T18:33:17.168798300Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:01.565076Z","iopub.execute_input":"2024-03-06T08:00:01.565415Z","iopub.status.idle":"2024-03-06T08:00:10.170342Z","shell.execute_reply.started":"2024-03-06T08:00:01.565391Z","shell.execute_reply":"2024-03-06T08:00:10.169456Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nplt.title(\"Correlation matrix - brain tumor attributes\")\nsns.heatmap(round(training_tabular_mapped.corr().abs(), 2), annot=True, cmap='summer')","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T18:24:14.211001400Z","start_time":"2024-02-09T18:24:13.542445200Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:10.171597Z","iopub.execute_input":"2024-03-06T08:00:10.171911Z","iopub.status.idle":"2024-03-06T08:00:11.301531Z","shell.execute_reply.started":"2024-03-06T08:00:10.171885Z","shell.execute_reply":"2024-03-06T08:00:11.300548Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Regplot between the target variable and each feature\ntargets = [\"Is Glioma\", \"Is Meningioma\", \"Is No tumor\", \"Is Pituitary\"]\n\ndef colors(column):\n    if column in X1.columns:\n        return 'orange'\n    elif column in targets :\n        return 'red'\n    else:\n        return 'blue'\n\nfig, axes = plt.subplots(5, 4, figsize=(12, 16))\naxes = axes.ravel()\n\nk = 0\n# Only remember the most correlated values\nfor tar in targets:\n    Xcorr = X[[col for col in X.columns if abs(training_tabular_mapped.corr()[col][tar]) >= 0.30]]\n    \n    for i, column in enumerate(Xcorr.columns):\n        if column not in targets:\n            sns.regplot(data=training_tabular_mapped, x=column, y=tar, ax=axes[k], color=colors(column))\n            axes[k].set_title(f'Regression Plot\\n({column} vs. {tar})')\n            k += 1\n    \n    plt.tight_layout()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T19:04:22.265418200Z","start_time":"2024-02-09T19:04:05.603472300Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:11.302833Z","iopub.execute_input":"2024-03-06T08:00:11.303173Z","iopub.status.idle":"2024-03-06T08:00:25.86657Z","shell.execute_reply.started":"2024-03-06T08:00:11.303143Z","shell.execute_reply":"2024-03-06T08:00:25.865692Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The graph above gives us an efficient way to separate the tumors from the healthy brains:","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=training_tabular_mapped['Contrast'].apply(np.log1p), y='Energy', hue=\"Is No tumor\", data=training_tabular_mapped)\n\nplt.xlabel('Log(Contrast + 1)') \nplt.ylabel('Energy')\nplt.title('Comparison between Energy and Contrast for tumor detection')\nplt.show()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T19:08:52.828855200Z","start_time":"2024-02-09T19:08:52.420830600Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:25.867864Z","iopub.execute_input":"2024-03-06T08:00:25.868218Z","iopub.status.idle":"2024-03-06T08:00:26.308736Z","shell.execute_reply.started":"2024-03-06T08:00:25.868184Z","shell.execute_reply":"2024-03-06T08:00:26.307829Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's make a short test to see what precision we can get with a simple model and only these two features:","metadata":{}},{"cell_type":"code","source":"training_tabular_mapped['Log_Contrast'] = training_tabular_mapped['Contrast'].apply(np.log1p)\n\n# Perform k-means clustering\nkmeans = KMeans(n_clusters=2, random_state=RANDOM_SEED)\nfeatures = training_tabular_mapped[['Log_Contrast', 'Energy']]\nkmeans.fit(features)\n\n# Predict the clusters\nclusters = kmeans.predict(features)\ntraining_tabular_mapped['Cluster'] = clusters\n\n# Plotting the scatter plot with the original data\nsns.scatterplot(x='Log_Contrast', y='Energy', hue=\"Is No tumor\", data=training_tabular_mapped, alpha=0.5)\n\n# Create a mesh grid for the background color of K-Means clustering\nx_min, x_max = training_tabular_mapped['Log_Contrast'].min() - 1, training_tabular_mapped['Log_Contrast'].max() + 1\ny_min, y_max = training_tabular_mapped['Energy'].min() -0.1, training_tabular_mapped['Energy'].max() + 0.1\nxx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n\n# Predict the cluster for each mesh point and reshape to the meshgrid shape\nZ = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\ndef map_clusters_to_labels(row):\n    if row['Is No tumor'] == 1:\n        return 1 if row['Cluster'] == cluster_label_for_no_tumor else 0\n    else:\n        return 0 if row['Cluster'] == cluster_label_for_no_tumor else 1\n\n# You might need to manually inspect or use a heuristic to determine which cluster corresponds to \"No tumor\"\n# For example, if cluster 0 mostly consists of \"No tumor\" points:\ncluster_label_for_no_tumor = 1  # This is an assumption, adjust based on your data\n\n# Map cluster labels to binary labels\nmapped_labels = training_tabular_mapped.apply(map_clusters_to_labels, axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(training_tabular_mapped['Is No tumor'], mapped_labels)\nprint(f\"Accuracy of GMM clustering: {accuracy}\")\n\n# Plot the regions\nplt.contourf(xx, yy, Z, alpha=0.15, cmap='coolwarm_r')\n\nplt.xlabel('Log(Contrast + 1)')\nplt.ylabel('Energy')\nplt.title(f'Applying Kmeans Classification for Tumor Detection (accuracy: {round(accuracy*100, 1)}%)')\nplt.show()\n\ntraining_tabular_mapped.drop(columns=[\"Cluster\", \"Log_Contrast\"], inplace=True)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T20:04:20.790106500Z","start_time":"2024-02-09T20:04:19.953172800Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:26.310095Z","iopub.execute_input":"2024-03-06T08:00:26.310813Z","iopub.status.idle":"2024-03-06T08:00:27.990393Z","shell.execute_reply.started":"2024-03-06T08:00:26.310754Z","shell.execute_reply":"2024-03-06T08:00:27.989436Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.scatterplot(x='Homogeneity', y=training_tabular_mapped['Standard Deviation'].apply(np.log1p), hue=\"Is Glioma\", data=training_tabular_mapped)\n\nplt.xlabel('Homogeneity') \nplt.ylabel('Log(Standard Deviation + 1)')\nplt.title('Comparison between Homogeneity and Standard Deviation for Glioma detection')\nplt.show()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-09T19:08:55.273213600Z","start_time":"2024-02-09T19:08:54.985925400Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:27.991915Z","iopub.execute_input":"2024-03-06T08:00:27.992246Z","iopub.status.idle":"2024-03-06T08:00:28.495872Z","shell.execute_reply.started":"2024-03-06T08:00:27.992217Z","shell.execute_reply":"2024-03-06T08:00:28.494926Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.scatterplot(x='Energy', y='Skewness', hue=\"Is Pituitary\", data=training_tabular_mapped)\n\nplt.xlabel('Energy')\nplt.ylabel('Skewness')\nplt.title('Comparison between Energy and Skewness for Pituitary detection')\nplt.show()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-10T09:47:41.326282500Z","start_time":"2024-02-10T09:47:40.478752700Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:28.497193Z","iopub.execute_input":"2024-03-06T08:00:28.497609Z","iopub.status.idle":"2024-03-06T08:00:28.936167Z","shell.execute_reply.started":"2024-03-06T08:00:28.49757Z","shell.execute_reply":"2024-03-06T08:00:28.935162Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_tabular_mapped['LogCont*Ener'] = np.log1p(training_tabular_mapped['Contrast']) * training_tabular_mapped['Energy']\ntraining_tabular_mapped['LogStd*Homo'] = np.log1p(training_tabular_mapped['Standard Deviation']) * training_tabular_mapped['Homogeneity']\ntraining_tabular_mapped['Skew*Ener'] = training_tabular_mapped['Skewness'] * training_tabular_mapped['Energy']\n\ncorr_matrix = training_tabular_mapped[targets + ['LogCont*Ener', 'LogStd*Homo', 'Skew*Ener']].corr().abs()\n\nplt.figure(figsize=(10, 6))\nplt.title(\"Correlation matrix - new features against targets\")\nsns.heatmap(corr_matrix.loc[['LogCont*Ener', 'LogStd*Homo', 'Skew*Ener'], targets], annot=True, cmap='summer', center=0)\nplt.show()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-10T09:48:13.333005400Z","start_time":"2024-02-10T09:48:13.001343500Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:28.937524Z","iopub.execute_input":"2024-03-06T08:00:28.937916Z","iopub.status.idle":"2024-03-06T08:00:29.216442Z","shell.execute_reply.started":"2024-03-06T08:00:28.937884Z","shell.execute_reply":"2024-03-06T08:00:29.215591Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Those new features are encouraging, though:\n- No Tumor already has 0.6 linear correlations with existing features\n- Same for Glioma: some features have a 0.4 correlation\n- Meningioma doesn't have significative linear correlations with tabular data\n\nHowever, remember that linear correlation only shows one type of correlation, that is less precise than our graph analysis above. We will keep those new 3 features.","metadata":{}},{"cell_type":"code","source":"training_final = training_tabular_mapped.copy()\ntraining_final.describe()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-10T10:03:52.505930300Z","start_time":"2024-02-10T10:03:51.755794600Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:29.217634Z","iopub.execute_input":"2024-03-06T08:00:29.217897Z","iopub.status.idle":"2024-03-06T08:00:29.278431Z","shell.execute_reply.started":"2024-03-06T08:00:29.217874Z","shell.execute_reply":"2024-03-06T08:00:29.277592Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply same transformations on the testing set\ntesting_final = testing_tabular.drop(columns=[\"Resolution\"])\ntesting_final['Is Glioma'] = (testing_final['Class'] == 'Glioma').astype(int)\ntesting_final['Is Meningioma'] = (testing_final['Class'] == 'Meningioma').astype(int)\ntesting_final['Is No tumor'] = (testing_final['Class'] == 'No tumor').astype(int)\ntesting_final['Is Pituitary'] = (testing_final['Class'] == 'Pituitary').astype(int)\ntesting_final = testing_final.drop(columns=[\"Class\"])\ntesting_final['LogCont*Ener'] = np.log1p(testing_final['Contrast']) * testing_final['Energy']\ntesting_final['LogStd*Homo'] = np.log1p(testing_final['Standard Deviation']) * testing_final['Homogeneity']\ntesting_final['Skew*Ener'] = testing_final['Skewness'] * testing_final['Energy']\n\ntesting_final.head()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-10T10:01:29.626202Z","start_time":"2024-02-10T10:01:29.169123Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:29.279379Z","iopub.execute_input":"2024-03-06T08:00:29.279644Z","iopub.status.idle":"2024-03-06T08:00:29.31289Z","shell.execute_reply.started":"2024-03-06T08:00:29.279621Z","shell.execute_reply":"2024-03-06T08:00:29.311896Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Testing Regular Machine Learning Models\n\nThe preprocessing is very simplified compaired to standard machine learning problems, as we have no null values, no categorical values, and the target were already manually one-hot encoded.","metadata":{}},{"cell_type":"code","source":"training_final.head() # Verify that all features are present","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:00:29.313892Z","iopub.execute_input":"2024-03-06T08:00:29.314129Z","iopub.status.idle":"2024-03-06T08:00:29.33673Z","shell.execute_reply.started":"2024-03-06T08:00:29.314107Z","shell.execute_reply":"2024-03-06T08:00:29.335885Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = training_final.drop(['Is Glioma', 'Is Meningioma', 'Is No tumor', 'Is Pituitary'], axis=1)\ntargets = training_final[['Is Glioma', 'Is Meningioma', 'Is No tumor', 'Is Pituitary']]\n\nprint(\"Features used for training:\", features.columns.tolist())\nprint(f\"Number of features dropped: {len(training_final.columns.tolist()) - len(features.columns.tolist())}\\n\")\n\n# Define the preprocessing for numerical columns\nnumerical_features = features.columns\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('pca', PCA(n_components=0.95))  # Reduce dimensionality\n])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_features),\n    ])\n\nclassifiers = {\n    'Logistic Regression': MultiOutputClassifier(LogisticRegression(random_state=RANDOM_SEED)),\n    'SVC': MultiOutputClassifier(SVC(random_state=RANDOM_SEED, probability=True)),\n    'Random Forest': MultiOutputClassifier(RandomForestClassifier(random_state=RANDOM_SEED)),\n    'Gradient Boosting': MultiOutputClassifier(GradientBoostingClassifier(random_state=RANDOM_SEED)),\n    'LightGBM': MultiOutputClassifier(lgb.LGBMClassifier(random_state=RANDOM_SEED, verbose=0)),\n    'XGBoost': MultiOutputClassifier(xgb.XGBClassifier(random_state=RANDOM_SEED, use_label_encoder=False, eval_metric='logloss'))\n}\n\n# Iterate through classifiers and create a pipeline for each\nfor name, classifier in classifiers.items():\n    pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('classifier', classifier)\n    ])\n\n    # Train the model with all training data\n    pipeline.fit(features, targets)\n\n    # Separate features and targets for the validation set\n    features_validation = testing_final.drop(['Is Glioma', 'Is Meningioma', 'Is No tumor', 'Is Pituitary'], axis=1)\n    targets_validation = testing_final[['Is Glioma', 'Is Meningioma', 'Is No tumor', 'Is Pituitary']]\n\n    # Use the pipeline to predict on the validation set\n    predictions_validation = pipeline.predict(features_validation)\n\n    # Converting one-hot encoded predictions and true values back to single label format for accuracy calculation\n    predictions_labels = np.argmax(predictions_validation, axis=1)\n    true_labels = np.argmax(targets_validation.to_numpy(), axis=1)\n\n    # Calculate accuracy\n    accuracy_validation = accuracy_score(true_labels, predictions_labels)\n    print(f\"{name} Validation set accuracy: {accuracy_validation:.4f}\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-10T10:46:54.092798800Z","start_time":"2024-02-10T10:46:34.881948700Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:29.343177Z","iopub.execute_input":"2024-03-06T08:00:29.343532Z","iopub.status.idle":"2024-03-06T08:00:48.652774Z","shell.execute_reply.started":"2024-03-06T08:00:29.343508Z","shell.execute_reply":"2024-03-06T08:00:48.651886Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Special pipeline for Catboost with Pool, which is a different kind of preprocessing but usually very efficient:","metadata":{}},{"cell_type":"code","source":"targets_single_col = np.argmax(targets.to_numpy(), axis=1)\n\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(features)\n\n# Create a Pool object for training\ntrain_pool = Pool(data=features_scaled, label=targets_single_col)\n\n# Initialize CatBoostClassifier with the appropriate evaluation metric for multi-class classification\ncatboost_model = CatBoostClassifier(random_seed=RANDOM_SEED, verbose=0, eval_metric='MultiClass')\n\n# Train the CatBoost model\ncatboost_model.fit(train_pool)\n\n# Prepare the validation set similarly\nfeatures_validation_scaled = scaler.transform(testing_final.drop(['Is Glioma', 'Is Meningioma', 'Is No tumor', 'Is Pituitary'], axis=1))\n\n# Convert one-hot encoded validation targets to a single label column\ntargets_validation_single_col = np.argmax(testing_final[['Is Glioma', 'Is Meningioma', 'Is No tumor', 'Is Pituitary']].to_numpy(), axis=1)\n\n# Create a Pool object for validation\nvalidation_pool = Pool(data=features_validation_scaled, label=targets_validation_single_col)\n\n# Predict using the trained CatBoost model on the validation set\npredictions_validation = catboost_model.predict(validation_pool)\n\n# Since we've converted the validation targets to a single column of labels,\n# the predictions from CatBoost are already in the correct format for accuracy calculation\ncatboost_accuracy_validation = accuracy_score(targets_validation_single_col, predictions_validation.flatten())\n\nprint(f\"CatBoost Validation set accuracy: {catboost_accuracy_validation:.4f}\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-10T10:49:02.062923600Z","start_time":"2024-02-10T10:48:53.658761200Z"},"execution":{"iopub.status.busy":"2024-03-06T08:00:48.656473Z","iopub.execute_input":"2024-03-06T08:00:48.658889Z","iopub.status.idle":"2024-03-06T08:00:57.247766Z","shell.execute_reply.started":"2024-03-06T08:00:48.658853Z","shell.execute_reply":"2024-03-06T08:00:57.246809Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Conclusion\n\n`CatBoost` is the best model so far. It reached 91% accuracy without needing a GPU, so we expect our ANN to perform much better.","metadata":{}},{"cell_type":"markdown","source":"# 6. Using Keras to train an ANN\n\nWe will start from scratch, and use the `Sequential` model from `Keras`.\n\n## 6.1 Define directories","metadata":{}},{"cell_type":"code","source":"img_size = (299, 299)\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:00:57.249026Z","iopub.execute_input":"2024-03-06T08:00:57.249854Z","iopub.status.idle":"2024-03-06T08:00:57.25429Z","shell.execute_reply.started":"2024-03-06T08:00:57.249817Z","shell.execute_reply":"2024-03-06T08:00:57.253168Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = p('Training')\nvalid_dir = p('Testing')\n\nresized_train_dir = o('Resized/Training')\nresized_valid_dir = o('Resized/Testing')\n\n# Create the \"Resized\" directories and subdirectories for each class if they don't exist\nos.makedirs(resized_train_dir, exist_ok=True)\nos.makedirs(resized_valid_dir, exist_ok=True)\n\nclass_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n\n# Create subdirectories in \"Resized\" for each class\nfor class_name in class_names:\n    os.makedirs(os.path.join(resized_train_dir, class_name), exist_ok=True)\n    os.makedirs(os.path.join(resized_valid_dir, class_name), exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:00:57.255543Z","iopub.execute_input":"2024-03-06T08:00:57.255851Z","iopub.status.idle":"2024-03-06T08:00:57.265661Z","shell.execute_reply.started":"2024-03-06T08:00:57.255827Z","shell.execute_reply":"2024-03-06T08:00:57.264703Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.2 Preprocess the data\n\n### Change image format from (w, y, z) to (299, 299, 1)","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\ndef resize_images(image_directory, img_size, savedir):\n    # Ensure the base save directory exists\n    if not os.path.exists(savedir):\n        os.makedirs(savedir)\n\n    for subdir, dirs, files in os.walk(image_directory):\n        print(f\"Processing directory: {subdir}\")\n        # Skip the base directory if it doesn't contain images directly\n        if not files:\n            continue\n\n        current_class = os.path.basename(subdir)  # More portable than splitting on \"/\"\n        print(f\"Current class: {current_class}\")\n\n        new_savedir = os.path.join(savedir, current_class)\n\n        # Create the class-specific save directory if it doesn't exist\n        if not os.path.exists(new_savedir):\n            os.makedirs(new_savedir)\n\n        for file in tqdm(files):\n            img_path = os.path.join(subdir, file)\n            img_savedir = os.path.join(new_savedir, file)\n\n            try:\n                img = load_img(img_path)\n                img_array = img_to_array(img)\n                # Select the first channel if there are several\n                if img_array.shape[-1] > 1:\n                    img_array = img_array[..., :1]\n                # Convert array back to image\n                img = array_to_img(img_array, scale=False)\n                # Resize the image\n                img = img.resize(img_size)\n                # Save the resized image\n                img.save(img_savedir)\n            except Exception as e:\n                print(f\"Error processing {img_path}: {e}\")\n\nresize_images(train_dir, img_size, o(\"Resized/Training\"))\nresize_images(valid_dir, img_size, o(\"Resized/Testing\"))\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    resized_train_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    color_mode='grayscale'  # Use grayscale since we're resizing to a single channel\n)\n\nvalid_generator = valid_datagen.flow_from_directory(\n    resized_valid_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    color_mode='grayscale'\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:00:57.267475Z","iopub.execute_input":"2024-03-06T08:00:57.26778Z","iopub.status.idle":"2024-03-06T08:01:38.434002Z","shell.execute_reply.started":"2024-03-06T08:00:57.267744Z","shell.execute_reply":"2024-03-06T08:01:38.433232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Verifying all images are (299, 299, 1) now","metadata":{}},{"cell_type":"code","source":"def verify_size():\n    tr_glioma = Collection(directory_path=o(\"Resized/Training/glioma\"), name=p(\"Glioma (training)\"), verbose=1)\n    tr_meningioma = Collection(directory_path=o(\"Resized/Training/meningioma\"), name=p(\"Meningioma (training)\"), verbose=1)\n    tr_notumor = Collection(directory_path=o(\"Resized/Training/notumor\"), name=p(\"No tumor (training)\"), verbose=1)\n    tr_pituitary = Collection(directory_path=o(\"Resized/Training/pituitary\"), name=p(\"Pituitary (training)\"), verbose=1)\n\n    te_glioma = Collection(directory_path=o(\"Resized/Testing/glioma\"), name=p(\"Glioma (testing)\"), verbose=1)\n    te_meningioma = Collection(directory_path=o(\"Resized/Testing/meningioma\"), name=p(\"Meningioma (testing)\"), verbose=1)\n    te_notumor = Collection(directory_path=o(\"Resized/Testing/notumor\"), name=p(\"No tumor (testing)\"), verbose=1)\n    te_pituitary = Collection(directory_path=o(\"Resized/Testing/pituitary\"), name=p(\"Pituitary (testing)\"), verbose=1)\n\n    print(\"Training and testing sets have been successfully loaded.\")\n\n    training_collections = [tr_glioma, tr_meningioma, tr_notumor, tr_pituitary]\n    testing_collections = [te_glioma, te_meningioma, te_notumor, te_pituitary]\n    all_collections = training_collections + testing_collections\n\n    del tr_glioma, tr_meningioma, tr_notumor, tr_pituitary\n    del te_glioma, te_meningioma, te_notumor, te_pituitary\n\n    # Create a header for the printing table\n    print(f\"{'Collection Name':<25} {'Content Type':<10} {'Format':<20}\")\n    print('-' * 60)  # Print a dividing line for headers\n\n    # Loop through each collection and print the details in a formatted row\n    for col in all_collections:\n        col.check_dimension_consistency()\n        col.check_image_format_consistency()\n\n        # Determine content type\n        if col.dimension_consistency and not col.iscolor:\n            content_type = \"Fully Grayscale\"\n        elif col.dimension_consistency and col.iscolor:\n            content_type = \"Fully Colored\"\n        else:\n            content_type = \"Mixed\"\n\n        # Determine format consistency\n        format_consistency = f\"Unique Shape {col.format}\" if col.format_consistency else \"Different Shapes\"\n\n        # Print the collection details in a formatted row\n        print(f\"{col.name:<25} {content_type:<10} {format_consistency:<20}\")\n\n    del training_collections, testing_collections, all_collections\n    \n\n# verify_size() <-- in comment because takes a lot of memory","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:01:38.435265Z","iopub.execute_input":"2024-03-06T08:01:38.435552Z","iopub.status.idle":"2024-03-06T08:01:38.446725Z","shell.execute_reply.started":"2024-03-06T08:01:38.435527Z","shell.execute_reply":"2024-03-06T08:01:38.4458Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:01:38.447918Z","iopub.execute_input":"2024-03-06T08:01:38.448325Z","iopub.status.idle":"2024-03-06T08:01:38.859495Z","shell.execute_reply.started":"2024-03-06T08:01:38.448295Z","shell.execute_reply":"2024-03-06T08:01:38.85848Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.3 Build the Convolutional Neural Network\n\n### First idea: self building the CNN layers\n\n#### Architechture of \"model1\"\n\n![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F17037041%2Fe5b1ba0658d1dea1264783608c206e7c%2Fcnn.png?generation=1712668296423150&alt=media)\n\n### Second idea: use the XCeption pre-built model\n\n#### Architechture of \"model2\"\n\n![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F17037041%2F68f246630994692a95787639af879adc%2FNeural4.png?generation=1709490059509918&alt=media))\n\n#### Architechture of XCeption\n\n![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F17037041%2F7f742589a66b82a394b78f4f257e8d7c%2Fxception.png?generation=1712668344529154&alt=media)","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 1)),\n    MaxPooling2D(2, 2),\n    \n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    \n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    \n    Flatten(),\n    Dense(512, activation='relu'),\n    Dropout(0.2),\n    Dense(4, activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:01:38.860904Z","iopub.execute_input":"2024-03-06T08:01:38.861353Z","iopub.status.idle":"2024-03-06T08:01:39.613041Z","shell.execute_reply.started":"2024-03-06T08:01:38.861319Z","shell.execute_reply":"2024-03-06T08:01:39.611988Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_shape=(img_size[0],img_size[1],1)\n\nduplicate_channels = Lambda(lambda x: tf.tile(x, [1, 1, 1, 3]))\ninput_layer = Input(shape=img_shape)\nx = duplicate_channels(input_layer)\n\n# Load the base model, excluding its top layer, designed to handle RGB images\nbase_model = Xception(include_top=False, weights=\"imagenet\", input_tensor=x, pooling='max')\n\n\nmodel2 = Sequential([\n    base_model,\n    Flatten(),\n    Dropout(rate= 0.3),\n    Dense(128, activation= 'relu'),\n    Dropout(rate= 0.25),\n    Dense(4, activation= 'softmax')\n])\n\nmodel2.compile(Adamax(learning_rate= 0.001),\n              loss= 'categorical_crossentropy',\n              metrics= ['accuracy',\n                        Precision(),\n                        Recall()])\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:00:46.920473Z","iopub.execute_input":"2024-03-06T10:00:46.921179Z","iopub.status.idle":"2024-03-06T10:00:48.812051Z","shell.execute_reply.started":"2024-03-06T10:00:46.921148Z","shell.execute_reply":"2024-03-06T10:00:48.811144Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.4 Train the model","metadata":{}},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:01:42.399172Z","iopub.execute_input":"2024-03-06T08:01:42.399486Z","iopub.status.idle":"2024-03-06T08:01:42.715446Z","shell.execute_reply.started":"2024-03-06T08:01:42.399459Z","shell.execute_reply":"2024-03-06T08:01:42.714338Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,\n    epochs=60,\n    validation_data=valid_generator,\n    validation_steps=valid_generator.samples // batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:01:42.717114Z","iopub.execute_input":"2024-03-06T08:01:42.717458Z","iopub.status.idle":"2024-03-06T08:36:30.282358Z","shell.execute_reply.started":"2024-03-06T08:01:42.717432Z","shell.execute_reply":"2024-03-06T08:36:30.281511Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T08:36:30.283651Z","iopub.execute_input":"2024-03-06T08:36:30.283988Z","iopub.status.idle":"2024-03-06T08:36:30.603679Z","shell.execute_reply.started":"2024-03-06T08:36:30.28396Z","shell.execute_reply":"2024-03-06T08:36:30.602688Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history2 = model2.fit(train_generator,\n                 epochs=20,\n                 validation_data=valid_generator,\n                 shuffle= False)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:00:54.387831Z","iopub.execute_input":"2024-03-06T10:00:54.388172Z","iopub.status.idle":"2024-03-06T10:54:24.270906Z","shell.execute_reply.started":"2024-03-06T10:00:54.388146Z","shell.execute_reply":"2024-03-06T10:54:24.27004Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_history(model, history):\n    # Extracting loss and accuracy for plotting\n    training_loss = history.history['loss']\n    training_accuracy = history.history['accuracy']\n    validation_loss = history.history['val_loss']\n    validation_accuracy = history.history['val_accuracy']\n    epochs = range(1, len(training_loss) + 1)\n\n    # Plotting training and validation loss\n    plt.figure(figsize=(14, 7))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, training_loss, 'bo-', label='Training Loss')\n    plt.plot(epochs, validation_loss, 'ro-', label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    # Plotting training and validation accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, training_accuracy, 'bo-', label='Training Accuracy')\n    plt.plot(epochs, validation_accuracy, 'ro-', label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n    \n\nplot_history(model, history)\nplot_history(model2, history2)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:54:24.272677Z","iopub.execute_input":"2024-03-06T10:54:24.273005Z","iopub.status.idle":"2024-03-06T10:54:25.307745Z","shell.execute_reply.started":"2024-03-06T10:54:24.27298Z","shell.execute_reply":"2024-03-06T10:54:25.306806Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def val_acc_for_higher_test_acc(history):\n    training_accuracy = history.history['accuracy']\n    validation_accuracy = history.history['val_accuracy']\n    highest_training_accuracy_epoch = np.argmax(training_accuracy)\n    \n    return validation_accuracy[highest_training_accuracy_epoch]\n\n\naccuracies = {\n    'Conv2D Val Accuracy': val_acc_for_higher_test_acc(history),\n    'Catboost Val Accuracy': catboost_accuracy_validation,\n    'XCeption Val Accuracy': val_acc_for_higher_test_acc(history2),\n}\n\n# Create a bar plot\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()))\nax.set(ylim=(0.88, 1.0))\n\n# Adding the text labels on the bars\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.2%'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 4), \n                textcoords = 'offset points')\n\nplt.title(f'Final Model Accuracy')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:54:25.308983Z","iopub.execute_input":"2024-03-06T10:54:25.309289Z","iopub.status.idle":"2024-03-06T10:54:25.513697Z","shell.execute_reply.started":"2024-03-06T10:54:25.309263Z","shell.execute_reply":"2024-03-06T10:54:25.51276Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion\n\nThe XCeption model achieves a 99.8% validation accuracy, which is much better than any other model developped in this notebook.","metadata":{}}]}